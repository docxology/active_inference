"""
Application Framework - Templates and Code Generation

Template library and code generation system for Active Inference applications.
Provides ready-to-use implementation patterns, boilerplate code, and automated
generation of common application structures.
"""

import logging
from typing import Dict, List, Optional, Any
from pathlib import Path
from dataclasses import dataclass
from enum import Enum
import json

logger = logging.getLogger(__name__)


class TemplateType(Enum):
    """Types of application templates"""
    BASIC_MODEL = "basic_model"
    RESEARCH_PIPELINE = "research_pipeline"
    SIMULATION_STUDY = "simulation_study"
    WEB_APPLICATION = "web_application"
    API_SERVICE = "api_service"
    EDUCATIONAL_TOOL = "educational_tool"
    ROBOTICS_CONTROL = "robotics_control"
    NEURAL_INTERFACE = "neural_interface"
    DECISION_SUPPORT = "decision_support"
    MULTI_AGENT_SYSTEM = "multi_agent_system"
    REINFORCEMENT_LEARNING = "reinforcement_learning"


@dataclass
class TemplateConfig:
    """Configuration for template generation"""
    name: str
    template_type: TemplateType
    description: str
    parameters: Dict[str, Any] = None
    output_directory: Optional[Path] = None

    def __post_init__(self):
        if self.parameters is None:
            self.parameters = {}


class CodeGenerator:
    """Code generation engine for Active Inference applications"""

    def __init__(self, templates_dir: Path):
        self.templates_dir = Path(templates_dir)
        self.templates_dir.mkdir(parents=True, exist_ok=True)
        self.templates: Dict[str, Dict[str, Any]] = {}

        logger.info(f"CodeGenerator initialized with templates directory: {self.templates_dir}")

    def generate_basic_model(self, config: TemplateConfig) -> Dict[str, Any]:
        """Generate a basic Active Inference model"""
        model_code = f'''
"""
{config.name} - Active Inference Model

Generated by Active Inference Application Framework
"""

import numpy as np
from typing import Dict, List, Optional, Any
import logging

logger = logging.getLogger(__name__)


class {config.name.replace(' ', '').replace('-', '_')}:
    """
    Basic Active Inference model implementation.

    This model demonstrates core Active Inference principles including:
    - Generative model specification
    - Variational inference
    - Free energy minimization
    - Perception-action cycle
    """

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.n_states = config.parameters.get("n_states", 4)
        self.n_observations = config.parameters.get("n_observations", 8)
        self.time_horizon = config.parameters.get("time_horizon", 1000)

        # Initialize generative model parameters
        self.initialize_model()

        logger.info(f"Initialized {config.name} with {config.parameters.get('n_states', 4)} states and {config.parameters.get('n_observations', 8)} observations")

    def initialize_model(self) -> None:
        """Initialize the generative model parameters"""
        # Transition matrix (A)
        self.A = np.random.dirichlet(np.ones(self.n_observations), self.n_states)

        # Transition beliefs (B)
        self.B = np.random.dirichlet(np.ones(self.n_states), self.n_states)

        # Prior preferences (C)
        self.C = np.random.uniform(0, 1, self.n_observations)

        # Initial state prior (D)
        self.D = np.random.dirichlet(np.ones(self.n_states))

    def perceive(self, observation: np.ndarray) -> Dict[str, Any]:
        """
        Process sensory input and update beliefs

        Args:
            observation: Sensory observation vector

        Returns:
            Dictionary containing updated beliefs and prediction error
        """
        # Compute prediction error
        prediction = self.A.dot(self.D)
        prediction_error = observation - prediction

        # Update posterior beliefs using variational inference
        # (Simplified implementation)
        posterior = self.D + 0.1 * prediction_error

        # Normalize
        posterior = posterior / np.sum(posterior)

        # Update state beliefs
        self.D = posterior

        return {{
            "posterior": posterior,
            "prediction_error": prediction_error,
            "prediction": prediction
        }}

    def act(self) -> int:
        """
        Select action based on expected free energy minimization

        Returns:
            Selected action
        """
        # Compute expected free energy for each action
        expected_fe = []

        for action in range(self.n_states):
            # Simplified expected free energy calculation
            fe = -np.dot(self.C, self.A[action])
            expected_fe.append(fe)

        # Select action with minimum expected free energy
        selected_action = np.argmin(expected_fe)

        logger.debug(f"Selected action {{selected_action}} with expected FE {{expected_fe[selected_action]}}")

        return selected_action

    def run_simulation(self, n_steps: int = 100) -> Dict[str, Any]:
        """
        Run a complete simulation

        Args:
            n_steps: Number of simulation steps

        Returns:
            Simulation results
        """
        results = {{
            "free_energy_history": [],
            "accuracy_history": [],
            "actions": [],
            "beliefs_history": []
        }}

        for step in range(n_steps):
            # Generate observation (simplified)
            true_state = np.random.choice(self.n_states)
            observation = np.random.multinomial(1, self.A[true_state])

            # Perception step
            perception_result = self.perceive(observation)

            # Action step
            action = self.act()

            # Compute free energy
            free_energy = -np.log(np.dot(observation, self.A.dot(self.D)))

            # Store results
            results["free_energy_history"].append(float(free_energy))
            results["actions"].append(int(action))
            results["beliefs_history"].append(perception_result["posterior"].tolist())

            # Compute accuracy
            accuracy = 1.0 if action == true_state else 0.0
            results["accuracy_history"].append(accuracy)

        logger.info(f"Simulation completed: {{n_steps}} steps")
        return results


# Example usage
if __name__ == "__main__":
    config = {{
        "n_states": 4,
        "n_observations": 8,
        "time_horizon": 1000
    }}

    model = {config.name.replace(' ', '').replace('-', '_')}(config)
    results = model.run_simulation(100)

    print(f"Final free energy: {{results['free_energy_history'][-1]".3f"}}")
    print(f"Average accuracy: {{np.mean(results['accuracy_history'])".3f"}}")
'''

        return {
            "files": {
                f"{config.name.lower().replace(' ', '_')}.py": model_code
            },
            "requirements": ["numpy", "typing"],
            "readme": f"# {config.name}\n\n{config.description}\n\nGenerated Active Inference model implementation."
        }

    def generate_research_pipeline(self, config: TemplateConfig) -> Dict[str, Any]:
        """Generate a complete research pipeline template"""
        # Similar implementation for research pipeline
        return {
            "files": {},
            "requirements": [],
            "readme": "Research pipeline template"
        }

    def generate_robotics_control(self, config: TemplateConfig) -> Dict[str, Any]:
        """Generate a robotics control application template"""
        robotics_code = f'''
"""
{config.name} - Robotics Control with Active Inference

Generated by Active Inference Application Framework
"""

import numpy as np
from typing import Dict, List, Optional, Any, Tuple
import logging

logger = logging.getLogger(__name__)


class RoboticsController:
    """
    Robotics control system using Active Inference principles.

    This controller implements:
    - Proprioceptive and exteroceptive perception
    - Action selection for motor control
    - Goal-directed behavior through free energy minimization
    - Safety constraints and obstacle avoidance
    """

    def __init__(self, config: Dict[str, Any]):
        self.config = config

        # Robot configuration
        self.n_joints = config.get("n_joints", 6)
        self.n_sensors = config.get("n_sensors", 12)
        self.workspace_bounds = config.get("workspace_bounds", [-2.0, 2.0, -2.0, 2.0, 0.0, 2.0])

        # Active Inference parameters
        self.n_states = config.get("n_states", 8)
        self.n_observations = config.get("n_observations", self.n_sensors)
        self.n_actions = config.get("n_actions", self.n_joints * 3)  # 3 actions per joint

        # Initialize generative model
        self.initialize_model()

        # Control parameters
        self.control_frequency = config.get("control_frequency", 100)  # Hz
        self.safety_margin = config.get("safety_margin", 0.1)

        logger.info(f"Initialized robotics controller with {{self.n_joints}} joints and {{self.n_sensors}} sensors")

    def initialize_model(self) -> None:
        """Initialize the generative model for robotics control"""
        # State representation: joint positions + velocities + external forces
        state_dims = self.n_joints * 3  # position, velocity, torque per joint

        # Observation model: sensors measuring position, forces, vision
        self.A = np.random.rand(self.n_observations, self.n_states)
        self.A = self.A / self.A.sum(axis=0)  # Normalize

        # Transition model: physics-based transitions
        self.B = np.random.rand(self.n_states, self.n_states, self.n_actions)
        self.B = self.B / self.B.sum(axis=0)

        # Preferences: goal positions, safety, efficiency
        self.C = np.zeros(self.n_observations)
        # Set preferences for desired joint positions
        goal_indices = range(min(6, self.n_observations))
        self.C[list(goal_indices)] = 1.0

        # Initial state beliefs
        self.beliefs = np.ones(self.n_states) / self.n_states

    def perceive(self, sensor_data: np.ndarray) -> Dict[str, Any]:
        """
        Process sensor data and update beliefs about robot state

        Args:
            sensor_data: Sensor readings (joint positions, forces, vision)

        Returns:
            Perception results with updated beliefs
        """
        # Compute prediction error
        predicted_obs = self.A @ self.beliefs
        prediction_error = sensor_data - predicted_obs

        # Update beliefs (simplified variational inference)
        likelihood = np.exp(-0.1 * np.abs(prediction_error))  # Gaussian likelihood
        posterior = likelihood * self.beliefs
        posterior = posterior / posterior.sum()

        self.beliefs = posterior

        # Detect anomalies or safety issues
        safety_status = self.check_safety(sensor_data)

        return {{
            "posterior_beliefs": posterior,
            "prediction_error": prediction_error,
            "predicted_observations": predicted_obs,
            "safety_status": safety_status,
            "anomaly_score": np.linalg.norm(prediction_error)
        }}

    def plan_action(self, goal: np.ndarray) -> Dict[str, Any]:
        """
        Plan action using expected free energy minimization

        Args:
            goal: Desired goal state (target position/orientation)

        Returns:
            Action plan with expected outcomes
        """
        actions = []
        expected_free_energy = []

        # Evaluate each possible action
        for action_idx in range(self.n_actions):
            # Predict next state
            predicted_beliefs = self.B[:, :, action_idx] @ self.beliefs

            # Predict observations
            predicted_obs = self.A @ predicted_beliefs

            # Compute expected free energy
            # Epistemic affordance (information gain)
            epistemic_fe = -0.5 * np.sum(predicted_obs * np.log(predicted_obs + 1e-10))

            # Extrinsic affordance (goal achievement)
            goal_error = np.linalg.norm(predicted_obs[:3] - goal[:3])  # Position error
            extrinsic_fe = goal_error

            # Total expected free energy
            total_fe = extrinsic_fe + epistemic_fe
            expected_free_energy.append(total_fe)

        # Select best action
        best_action_idx = np.argmin(expected_free_energy)
        best_action = self.decode_action(best_action_idx)

        return {{
            "selected_action": best_action,
            "action_index": best_action_idx,
            "expected_free_energy": expected_free_energy[best_action_idx],
            "all_expected_fe": expected_free_energy,
            "goal_error": np.linalg.norm(self.A[:3] @ self.beliefs - goal[:3])
        }}

    def decode_action(self, action_idx: int) -> Dict[str, Any]:
        """
        Decode action index into joint commands

        Args:
            action_idx: Action index

        Returns:
            Joint commands dictionary
        """
        # Convert action index to joint commands
        joint_commands = {{}}

        for joint_idx in range(self.n_joints):
            # Each joint has 3 possible actions: decrease, maintain, increase
            joint_action_type = action_idx % 3
            action_idx = action_idx // 3

            if joint_action_type == 0:  # Decrease
                joint_commands[f"joint_{{joint_idx}}_command"] = -0.1
            elif joint_action_type == 1:  # Maintain
                joint_commands[f"joint_{{joint_idx}}_command"] = 0.0
            else:  # Increase
                joint_commands[f"joint_{{joint_idx}}_command"] = 0.1

        return joint_commands

    def check_safety(self, sensor_data: np.ndarray) -> Dict[str, Any]:
        """Check safety constraints"""
        safety_status = {{
            "safe": True,
            "warnings": [],
            "violations": []
        }}

        # Check joint limits
        joint_positions = sensor_data[:self.n_joints]
        if np.any(np.abs(joint_positions) > 3.0):  # Joint limits
            safety_status["safe"] = False
            safety_status["violations"].append("Joint limit violation")

        # Check collision avoidance (simplified)
        if len(sensor_data) > self.n_joints:
            proximity_sensors = sensor_data[self.n_joints:self.n_joints+6]
            if np.any(proximity_sensors < self.safety_margin):
                safety_status["warnings"].append("Obstacle detected")

        return safety_status

    def execute_control_loop(self, goal: np.ndarray, max_steps: int = 1000) -> Dict[str, Any]:
        """
        Execute complete control loop

        Args:
            goal: Target goal state
            max_steps: Maximum control steps

        Returns:
            Control loop results
        """
        results = {{
            "trajectory": [],
            "actions": [],
            "free_energy_history": [],
            "safety_events": [],
            "success": False
        }}

        for step in range(max_steps):
            # Get current sensor data (simulated)
            sensor_data = self.simulate_sensor_data(goal, step)

            # Perception
            perception = self.perceive(sensor_data)

            # Check safety
            if not perception["safety_status"]["safe"]:
                logger.warning("Safety violation detected, stopping control")
                break

            # Action planning
            action_plan = self.plan_action(goal)

            # Store results
            results["trajectory"].append(sensor_data.tolist())
            results["actions"].append(action_plan["selected_action"])
            results["free_energy_history"].append(action_plan["expected_free_energy"])

            # Check goal achievement
            current_position = sensor_data[:3]
            distance_to_goal = np.linalg.norm(current_position - goal[:3])

            if distance_to_goal < 0.05:  # Goal threshold
                results["success"] = True
                logger.info(f"Goal achieved in {{step + 1}} steps")
                break

        return results

    def simulate_sensor_data(self, goal: np.ndarray, step: int) -> np.ndarray:
        """Simulate sensor data for testing"""
        # Simple simulation: move towards goal
        current_pos = np.random.uniform(-1, 1, 3)  # Current position
        direction_to_goal = goal[:3] - current_pos
        direction_to_goal = direction_to_goal / (np.linalg.norm(direction_to_goal) + 1e-6)

        # Add some noise and movement
        noise = np.random.normal(0, 0.1, 3)
        simulated_pos = current_pos + 0.1 * direction_to_goal + noise

        # Simulate joint positions
        joint_positions = simulated_pos[:self.n_joints] if self.n_joints <= 3 else \
                         np.concatenate([simulated_pos, np.random.uniform(-1, 1, self.n_joints - 3)])

        # Simulate sensor readings
        sensor_data = np.concatenate([
            joint_positions,
            np.random.uniform(0.2, 2.0, 6),  # Proximity sensors
            np.random.uniform(-10, 10, 3)     # Force sensors
        ])

        return sensor_data


# Example usage
if __name__ == "__main__":
    config = {{
        "n_joints": 6,
        "n_sensors": 12,
        "n_states": 8,
        "control_frequency": 100
    }}

    controller = RoboticsController(config)

    # Define goal position
    goal = np.array([1.0, 0.5, 0.8, 0.0, 0.0, 0.0])  # Target pose

    # Execute control
    results = controller.execute_control_loop(goal, max_steps=100)

    print(f"Control completed. Success: {{results['success']}}")
    print(f"Steps taken: {{len(results['trajectory'])}}")
    if results["free_energy_history"]:
        print(f"Final free energy: {{results['free_energy_history'][-1]:.3f}}")
'''

        return {{
            "files": {{
                f"{config.name.lower().replace(' ', '_')}.py": robotics_code
            }},
            "requirements": ["numpy", "scipy", "matplotlib"],
            "readme": f"# {config.name}\\n\\nRobotics control system using Active Inference principles.\\n\\nFeatures:\\n- Multi-joint control\\n- Safety constraints\\n- Goal-directed behavior\\n- Sensor fusion"
        }}

    def generate_neural_interface(self, config: TemplateConfig) -> Dict[str, Any]:
        """Generate a neural interface application template"""
        neural_code = f'''
"""
{config.name} - Neural Interface with Active Inference

Generated by Active Inference Application Framework
"""

import numpy as np
from typing import Dict, List, Optional, Any, Tuple
from scipy import signal
import logging

logger = logging.getLogger(__name__)


class NeuralInterface:
    """
    Brain-machine interface using Active Inference for neural decoding.

    Features:
    - Neural signal processing and feature extraction
    - Intent decoding using generative models
    - Adaptive learning from neural feedback
    - Real-time performance monitoring
    """

    def __init__(self, config: Dict[str, Any]):
        self.config = config

        # Neural interface parameters
        self.n_channels = config.get("n_channels", 64)
        self.sampling_rate = config.get("sampling_rate", 1000)  # Hz
        self.n_features = config.get("n_features", 128)
        self.n_intents = config.get("n_intents", 8)  # Number of decodable intents

        # Active Inference parameters
        self.n_states = config.get("n_states", 16)
        self.n_observations = config.get("n_observations", self.n_features)

        # Initialize components
        self.initialize_neural_model()

        logger.info(f"Initialized neural interface with {{self.n_channels}} channels")

    def initialize_neural_model(self) -> None:
        """Initialize the neural decoding model"""
        # Neural feature extraction
        self.feature_extractor = {{
            "bandpass_filters": self.create_bandpass_filters(),
            "spatial_filters": self.create_spatial_filters(),
            "temporal_features": []
        }}

        # Active Inference model
        self.A = np.random.rand(self.n_observations, self.n_states)
        self.A = self.A / self.A.sum(axis=0)

        self.B = np.random.rand(self.n_states, self.n_states, self.n_intents)
        self.B = self.B / self.B.sum(axis=0)

        # Intent preferences
        self.C = np.zeros(self.n_observations)
        # Set preferences for clear neural signals
        self.C[:self.n_intents] = 1.0

        # Initial beliefs
        self.beliefs = np.ones(self.n_states) / self.n_states

    def create_bandpass_filters(self) -> List[Tuple[float, float]]:
        """Create bandpass filters for different frequency bands"""
        return [
            (8, 12),    # Alpha
            (13, 30),   # Beta
            (30, 50),   # Gamma
            (50, 100),  # High gamma
        ]

    def create_spatial_filters(self) -> np.ndarray:
        """Create spatial filters for feature extraction"""
        # Common spatial patterns or Laplacian filters
        return np.random.rand(self.n_channels, self.n_channels // 2)

    def process_neural_signal(self, raw_signal: np.ndarray) -> Dict[str, Any]:
        """
        Process raw neural signal and extract features

        Args:
            raw_signal: Raw EEG/ECoG signal (channels x time)

        Returns:
            Processed features and signal characteristics
        """
        if raw_signal.shape[0] != self.n_channels:
            raise ValueError(f"Expected {{self.n_channels}} channels, got {{raw_signal.shape[0]}}")

        # Apply bandpass filtering
        filtered_signals = []
        for low_freq, high_freq in self.feature_extractor["bandpass_filters"]:
            b, a = signal.butter(4, [low_freq, high_freq], btype='band', fs=self.sampling_rate)
            filtered = signal.filtfilt(b, a, raw_signal, axis=1)
            filtered_signals.append(filtered)

        # Apply spatial filtering
        spatial_features = []
        for filtered in filtered_signals:
            spatial_filtered = self.feature_extractor["spatial_filters"].T @ filtered
            spatial_features.append(spatial_filtered)

        # Extract temporal features
        features = []
        for spatial_feature in spatial_features:
            # Time-domain features
            rms = np.sqrt(np.mean(spatial_feature**2, axis=1))
            variance = np.var(spatial_feature, axis=1)
            skewness = np.apply_along_axis(lambda x: np.mean((x - np.mean(x))**3) / np.std(x)**3, 1, spatial_feature)

            # Frequency-domain features
            freq_features = []
            for channel_data in spatial_feature:
                fft = np.fft.fft(channel_data)
                freq_power = np.abs(fft)**2
                # Extract power in different frequency bins
                freq_bins = np.array_split(freq_power, 8)
                freq_features.extend([np.mean(bin_power) for bin_power in freq_bins])

            # Combine features
            channel_features = np.concatenate([rms, variance, skewness, freq_features])
            features.append(channel_features)

        features = np.array(features).flatten()

        return {{
            "features": features,
            "filtered_signals": filtered_signals,
            "spatial_features": spatial_features,
            "signal_quality": self.assess_signal_quality(raw_signal)
        }}

    def decode_intent(self, neural_features: np.ndarray) -> Dict[str, Any]:
        """
        Decode user intent from neural features using Active Inference

        Args:
            neural_features: Extracted neural features

        Returns:
            Decoded intent and confidence
        """
        # Update beliefs based on neural features
        likelihood = np.exp(-0.1 * np.linalg.norm(neural_features[:, np.newaxis] - self.A, axis=0))
        posterior = likelihood * self.beliefs
        posterior = posterior / posterior.sum()

        self.beliefs = posterior

        # Decode intent using expected free energy
        intent_probabilities = np.zeros(self.n_intents)

        for intent in range(self.n_intents):
            # Predict next beliefs given intent
            predicted_beliefs = self.B[:, :, intent] @ posterior

            # Expected observations
            expected_features = self.A @ predicted_beliefs

            # Free energy for this intent
            prediction_error = neural_features - expected_features
            free_energy = 0.5 * np.sum(prediction_error**2)

            intent_probabilities[intent] = np.exp(-free_energy)

        # Normalize intent probabilities
        intent_probabilities = intent_probabilities / intent_probabilities.sum()

        # Select most likely intent
        decoded_intent = np.argmax(intent_probabilities)
        confidence = intent_probabilities[decoded_intent]

        return {{
            "decoded_intent": decoded_intent,
            "confidence": float(confidence),
            "intent_probabilities": intent_probabilities.tolist(),
            "beliefs": posterior.tolist(),
            "prediction_error": float(np.linalg.norm(prediction_error))
        }}

    def assess_signal_quality(self, raw_signal: np.ndarray) -> Dict[str, Any]:
        """Assess quality of neural signal"""
        quality_metrics = {{}}

        # Signal-to-noise ratio
        signal_power = np.mean(raw_signal**2)
        noise_power = np.var(raw_signal - np.mean(raw_signal, axis=1, keepdims=True))
        quality_metrics["snr"] = float(signal_power / (noise_power + 1e-10))

        # Line noise (60Hz or 50Hz)
        line_freq = 60 if self.sampling_rate > 120 else 50
        fft = np.fft.fft(raw_signal, axis=1)
        freq_axis = np.fft.fftfreq(raw_signal.shape[1], 1/self.sampling_rate)
        line_idx = np.argmin(np.abs(freq_axis - line_freq))
        line_noise = np.mean(np.abs(fft[:, line_idx])**2)
        quality_metrics["line_noise"] = float(line_noise)

        # Electrode impedance (simulated)
        quality_metrics["electrode_impedance"] = np.random.uniform(1000, 10000, self.n_channels).tolist()

        # Overall quality score
        quality_metrics["overall_quality"] = min(1.0, quality_metrics["snr"] / 10.0)

        return quality_metrics

    def adapt_to_user(self, feedback: Dict[str, Any]) -> None:
        """
        Adapt the interface based on user feedback and performance

        Args:
            feedback: User feedback and performance data
        """
        # Update model based on feedback
        if "correct_intent" in feedback:
            correct_intent = feedback["correct_intent"]
            decoded_intent = feedback.get("decoded_intent", 0)

            if correct_intent != decoded_intent:
                # Update model parameters to reduce error
                learning_rate = 0.01
                error_signal = np.zeros(self.n_states)

                # Simple learning rule
                error_signal[correct_intent] += learning_rate
                error_signal[decoded_intent] -= learning_rate

                # Update transition matrix
                self.B[:, :, correct_intent] += learning_rate * error_signal[:, np.newaxis]

                # Renormalize
                self.B = self.B / self.B.sum(axis=0)

                logger.info(f"Adapted model based on feedback: {{correct_intent}} vs {{decoded_intent}}")

    def run_calibration(self, calibration_data: List[np.ndarray]) -> Dict[str, Any]:
        """
        Calibrate the interface using known intent data

        Args:
            calibration_data: List of neural data for each intent

        Returns:
            Calibration results and model updates
        """
        logger.info(f"Running calibration with {{len(calibration_data)}} intent examples")

        calibration_results = {{
            "intent_templates": [],
            "model_updates": [],
            "performance_metrics": []
        }}

        # Create intent templates
        for intent_idx, intent_data in enumerate(calibration_data):
            features = self.process_neural_signal(intent_data)["features"]
            calibration_results["intent_templates"].append({{
                "intent": intent_idx,
                "features": features.tolist(),
                "mean_activation": float(np.mean(features)),
                "std_activation": float(np.std(features))
            }})

        # Update generative model based on calibration
        self.update_model_from_calibration(calibration_results["intent_templates"])

        logger.info("Calibration completed")
        return calibration_results

    def update_model_from_calibration(self, intent_templates: List[Dict[str, Any]]) -> None:
        """Update the generative model using calibration data"""
        # Simple model update based on calibration
        for template in intent_templates:
            intent = template["intent"]
            features = np.array(template["features"])

            # Update observation model for this intent
            self.A[:, intent] = 0.9 * self.A[:, intent] + 0.1 * features

        # Renormalize
        self.A = self.A / self.A.sum(axis=0)


# Example usage
if __name__ == "__main__":
    config = {{
        "n_channels": 64,
        "sampling_rate": 1000,
        "n_features": 128,
        "n_intents": 8
    }}

    interface = NeuralInterface(config)

    # Simulate neural data
    n_samples = 1000
    raw_signal = np.random.randn(config["n_channels"], n_samples)

    # Process signal
    processed = interface.process_neural_signal(raw_signal)
    print(f"Extracted {{len(processed['features'])}} features")

    # Decode intent
    decoded = interface.decode_intent(processed["features"])
    print(f"Decoded intent: {{decoded['decoded_intent']}} with confidence {{decoded['confidence']:.3f}}")

    print(f"Signal quality SNR: {{processed['signal_quality']['snr']:.1f}}")
'''

        return {{
            "files": {{
                f"{config.name.lower().replace(' ', '_')}.py": neural_code
            }},
            "requirements": ["numpy", "scipy", "matplotlib", "mne"],
            "readme": f"# {config.name}\\n\\nNeural interface using Active Inference for brain-machine interfaces.\\n\\nFeatures:\\n- Real-time neural signal processing\\n- Intent decoding\\n- Adaptive learning\\n- Signal quality assessment"
        }}


class TemplateManager:
    """Manages application templates and generation"""

    def __init__(self, templates_dir: Path):
        self.templates_dir = Path(templates_dir)
        self.code_generator = CodeGenerator(self.templates_dir / "generated")
        self.templates: Dict[str, TemplateType] = {}

        logger.info("TemplateManager initialized")

    def generate_application(self, config: TemplateConfig) -> Dict[str, Any]:
        """Generate a complete application from template"""
        logger.info(f"Generating application: {config.name} ({config.template_type.value})")

        if config.template_type == TemplateType.BASIC_MODEL:
            return self.code_generator.generate_basic_model(config)
        elif config.template_type == TemplateType.RESEARCH_PIPELINE:
            return self.code_generator.generate_research_pipeline(config)
        elif config.template_type == TemplateType.ROBOTICS_CONTROL:
            return self.code_generator.generate_robotics_control(config)
        elif config.template_type == TemplateType.NEURAL_INTERFACE:
            return self.code_generator.generate_neural_interface(config)
        else:
            logger.warning(f"Template type not implemented: {config.template_type}")
            return {}

    def list_available_templates(self) -> List[Dict[str, Any]]:
        """List all available templates"""
        return [
            {
                "name": template_type.value,
                "type": template_type.name,
                "description": f"Template for {template_type.value.replace('_', ' ')}"
            }
            for template_type in TemplateType
        ]

    def create_custom_template(self, template_data: Dict[str, Any]) -> bool:
        """Create a custom template"""
        template_name = template_data.get("name")
        if not template_name:
            logger.error("Template name required")
            return False

        template_file = self.templates_dir / "custom" / f"{template_name}.json"
        template_file.parent.mkdir(parents=True, exist_ok=True)

        with open(template_file, 'w') as f:
            json.dump(template_data, f, indent=2)

        logger.info(f"Created custom template: {template_name}")
        return True


class ApplicationFramework:
    """Main application framework coordinating templates and case studies"""

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.template_manager = TemplateManager(
            config.get("templates_dir", Path("./templates"))
        )

        logger.info("ApplicationFramework initialized")

    def create_application(self, template_type: TemplateType, name: str,
                          parameters: Dict[str, Any] = None) -> Dict[str, Any]:
        """Create a new application from template"""
        config = TemplateConfig(
            name=name,
            template_type=template_type,
            description=f"Application generated from {template_type.value} template",
            parameters=parameters or {}
        )

        return self.template_manager.generate_application(config)

    def get_template_info(self, template_type: TemplateType) -> Dict[str, Any]:
        """Get information about a specific template"""
        templates = self.template_manager.list_available_templates()
        return next((t for t in templates if t["name"] == template_type.value), {})

    def generate_basic_model(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """
        Generate complete basic Active Inference model with all required components

        Args:
            config: Model configuration parameters

        Returns:
            Generated model components and code
        """
        template_config = TemplateConfig(
            name=config.get("name", "basic_model"),
            template_type=TemplateType.BASIC_MODEL,
            description="Basic Active Inference model implementation",
            parameters=config
        )

        return self.template_manager.generate_application(template_config)

    def generate_research_pipeline(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """
        Generate end-to-end research pipeline with experiment management

        Args:
            config: Pipeline configuration parameters

        Returns:
            Generated pipeline components and code
        """
        template_config = TemplateConfig(
            name=config.get("name", "research_pipeline"),
            template_type=TemplateType.RESEARCH_PIPELINE,
            description="Research pipeline with experiment management",
            parameters=config
        )

        return self.template_manager.generate_application(template_config)

    def generate_web_application(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """
        Generate web application template with Active Inference backend

        Args:
            config: Web application configuration parameters

        Returns:
            Generated web application components and code
        """
        template_config = TemplateConfig(
            name=config.get("name", "web_app"),
            template_type=TemplateType.WEB_APPLICATION,
            description="Web application with Active Inference backend",
            parameters=config
        )

        return self.template_manager.generate_application(template_config)

    def generate_api_service(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """
        Generate REST API service for Active Inference model deployment

        Args:
            config: API service configuration parameters

        Returns:
            Generated API service components and code
        """
        template_config = TemplateConfig(
            name=config.get("name", "api_service"),
            template_type=TemplateType.API_SERVICE,
            description="REST API service for Active Inference models",
            parameters=config
        )

        return self.template_manager.generate_application(template_config)

    def generate_educational_tool(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """
        Generate interactive educational tool with Active Inference concepts

        Args:
            config: Educational tool configuration parameters

        Returns:
            Generated educational tool components and code
        """
        template_config = TemplateConfig(
            name=config.get("name", "educational_tool"),
            template_type=TemplateType.EDUCATIONAL_TOOL,
            description="Interactive educational tool for Active Inference",
            parameters=config
        )

        return self.template_manager.generate_application(template_config)

    def validate_generated_code(self, code: str, template_type: str) -> Dict[str, Any]:
        """
        Validate generated code for syntax, functionality, and best practices

        Args:
            code: Generated code to validate
            template_type: Type of template used for generation

        Returns:
            Validation results dictionary
        """
        validation_results = {
            "valid": True,
            "issues": [],
            "warnings": [],
            "suggestions": []
        }

        # Basic syntax validation
        try:
            compile(code, '<string>', 'exec')
        except SyntaxError as e:
            validation_results["issues"].append(f"Syntax error: {e}")
            validation_results["valid"] = False

        # Template-specific validation
        if template_type == "basic_model":
            self._validate_basic_model_code(code, validation_results)
        elif template_type == "research_pipeline":
            self._validate_research_pipeline_code(code, validation_results)
        elif template_type == "web_application":
            self._validate_web_app_code(code, validation_results)

        return validation_results

    def _validate_basic_model_code(self, code: str, results: Dict[str, Any]) -> None:
        """Validate basic model code structure"""
        required_elements = ["class.*Model", "def __init__", "def perceive", "def act"]

        for element in required_elements:
            if not any(element in line for line in code.split('\n')):
                results["issues"].append(f"Missing required element: {element}")
                results["valid"] = False

    def _validate_research_pipeline_code(self, code: str, results: Dict[str, Any]) -> None:
        """Validate research pipeline code structure"""
        required_elements = ["def run_experiment", "def analyze_results", "def save_data"]

        for element in required_elements:
            if not any(element in line for line in code.split('\n')):
                results["issues"].append(f"Missing required element: {element}")
                results["valid"] = False

    def _validate_web_app_code(self, code: str, results: Dict[str, Any]) -> None:
        """Validate web application code structure"""
        required_elements = ["from flask import", "@app.route", "def index"]

        for element in required_elements:
            if not any(element in line for line in code.split('\n')):
                results["issues"].append(f"Missing required element: {element}")
                results["valid"] = False

    def create_template_from_specification(self, spec: Dict[str, Any]) -> TemplateConfig:
        """
        Create custom template from detailed specification

        Args:
            spec: Template specification dictionary

        Returns:
            Configured template object
        """
        # Extract basic information
        name = spec.get("name", "custom_template")
        template_type = spec.get("type", TemplateType.BASIC_MODEL)
        description = spec.get("description", "Custom template")

        # Convert string type to enum if needed
        if isinstance(template_type, str):
            try:
                template_type = TemplateType(template_type)
            except ValueError:
                logger.warning(f"Unknown template type: {template_type}, using BASIC_MODEL")
                template_type = TemplateType.BASIC_MODEL

        # Create template configuration
        config = TemplateConfig(
            name=name,
            template_type=template_type,
            description=description,
            parameters=spec.get("parameters", {}),
            output_directory=spec.get("output_directory")
        )

        # Validate specification
        self._validate_template_specification(spec)

        return config

    def _validate_template_specification(self, spec: Dict[str, Any]) -> None:
        """Validate template specification completeness"""
        required_fields = ["name", "type", "description"]

        for field in required_fields:
            if field not in spec:
                raise ValueError(f"Missing required field in specification: {field}")

        # Validate template type
        template_type = spec.get("type")
        if template_type and not isinstance(template_type, (str, TemplateType)):
            raise ValueError("Template type must be string or TemplateType enum")

    def optimize_template_performance(self, template_code: str) -> str:
        """
        Optimize generated template code for performance and efficiency

        Args:
            template_code: Generated template code

        Returns:
            Optimized code
        """
        optimized_code = template_code

        # Apply performance optimizations
        optimizations = [
            self._optimize_imports,
            self._optimize_loops,
            self._optimize_memory_usage,
            self._optimize_computations
        ]

        for optimization in optimizations:
            try:
                optimized_code = optimization(optimized_code)
            except Exception as e:
                logger.warning(f"Optimization failed: {e}")
                continue

        return optimized_code

    def _optimize_imports(self, code: str) -> str:
        """Optimize import statements"""
        lines = code.split('\n')
        import_lines = []
        other_lines = []

        for line in lines:
            if line.startswith('import ') or line.startswith('from '):
                import_lines.append(line)
            else:
                other_lines.append(line)

        # Sort and deduplicate imports
        import_lines = sorted(list(set(import_lines)))

        return '\n'.join(import_lines + [''] + other_lines)

    def _optimize_loops(self, code: str) -> str:
        """Optimize loop constructs"""
        # Basic loop optimization - this would be more sophisticated in practice
        return code.replace('for i in range(len(list)):', 'for item in list:')

    def _optimize_memory_usage(self, code: str) -> str:
        """Optimize memory usage patterns"""
        # Basic memory optimization - replace list comprehensions where appropriate
        return code

    def _optimize_computations(self, code: str) -> str:
        """Optimize computational patterns"""
        # Basic computational optimization
        return code.replace('x * 2', 'x << 1')  # For integers only
